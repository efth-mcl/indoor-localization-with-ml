{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN Depth train example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -e ../package/\n",
    "import os\n",
    "\n",
    "\n",
    "from thesispack.models import *\n",
    "from thesispack.methods import gen_nx_graphs, A2G, graphs_stats\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewData = False\n",
    "DataId = 0\n",
    "saveData = False\n",
    "path = '../data/gcn-depth/GraphsDataset_{}.npy'\n",
    "if NewData:\n",
    "    want = [1,0,0,0,0,1,1,1]\n",
    "    examples = 300\n",
    "    minN = 6\n",
    "    maxN = 24\n",
    "\n",
    "    X, A, Ahat, C = next(iter(gen_nx_graphs(examples, want, minN, maxN)))\n",
    "    X = tf.cast(X,tf.float32)\n",
    "    A = tf.cast(A,tf.float32)\n",
    "    Ahat = tf.cast(Ahat,tf.float32)\n",
    "    C = LabelBinarizer().fit_transform(C)\n",
    "    C = tf.cast(C,tf.float32)\n",
    "    if saveData:\n",
    "        di = 0\n",
    "        while True:\n",
    "            if not os.path.exists(path.format(di)):\n",
    "                np.save(path.format(di),\n",
    "                    {\n",
    "                        \"A\": A,\n",
    "                        \"A_hat\": Ahat,\n",
    "                        \"X\": X,\n",
    "                        \"C\": C\n",
    "                })\n",
    "                break\n",
    "            di += 1\n",
    "\n",
    "else:\n",
    "    A, Ahat, X, C = np.load(path.format(DataId), allow_pickle=True).tolist().values()\n",
    "maxD, depth_dist, maxDs, edgesN = graphs_stats(A)\n",
    "train = tf.data.Dataset.from_tensor_slices((X,Ahat,C)).batch(128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = True\n",
    "\n",
    "vals = np.array(list(maxDs.values()))\n",
    "vals = vals/np.sum(vals)\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.bar(maxDs.keys(),vals)\n",
    "plt.xticks(list(maxDs.keys()))\n",
    "plt.xlabel(r'$Max \\; Depths \\; \\#$', fontsize=20)\n",
    "plt.ylabel(r'$Verteces \\; \\%$', fontsize=20)\n",
    "if save_fig:\n",
    "    plt.savefig('DataFigures/gcn-depth/{}.eps'.format('max-depth-dist'),format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "cmax = C.shape[1]\n",
    "for i in range(A.shape[0]):\n",
    "    if c == tf.argmax(C[i]):\n",
    "        c+=1\n",
    "        g = A2G(A[i])\n",
    "        plt.figure(figsize=(8,8))\n",
    "        nx.draw(g)\n",
    "    elif c == cmax:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN model Class Stracture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC(tf.Module):\n",
    "    def __init__(self, in_features,out_features,activation=None):\n",
    "        super(FC,self).__init__(name=\"fc\")\n",
    "\n",
    "        self.weights = tf.Variable(\n",
    "            tf.keras.initializers.GlorotUniform()(shape=[in_features, out_features]),\n",
    "            name='weights'\n",
    "        )\n",
    "        self.bais = tf.Variable(\n",
    "            tf.keras.initializers.GlorotUniform()(shape=[out_features]),\n",
    "            name='bais'\n",
    "        )\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def __call__(self,inputs):\n",
    "        x = tf.matmul(inputs,self.weights) + self.bais\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class GCNforDepth(tf.Module, Trainer):\n",
    "    def __init__(self,nf0,nc,depth=1,nfi=64):\n",
    "        tf.Module.__init__(self,name='my_gcn')\n",
    "        Trainer.__init__(self,1e-2)\n",
    "        self.depth = depth\n",
    "        self.__status = [\n",
    "            [0],\n",
    "            [0],\n",
    "            [1,2]\n",
    "        ]\n",
    "        self.score_mtr = MetricBase(self,\n",
    "            [tf.keras.metrics.CategoricalAccuracy()],\n",
    "            self.__status,\n",
    "            [0]\n",
    "        )\n",
    "        self.cost_mtr = MetricBase(self,\n",
    "            [tf.keras.metrics.CategoricalCrossentropy()],\n",
    "            self.__status,\n",
    "            [0],\n",
    "            1\n",
    "        )\n",
    "        self.cost_loss = LossBase(self,\n",
    "            # make custom cost\n",
    "            [tf.keras.losses.CategoricalCrossentropy()],\n",
    "            self.__status,\n",
    "            [0]\n",
    "        )\n",
    "        depthi = '1'\n",
    "        setattr(self, 'gcn{}'.format(depthi), GCN(nf0,nfi,'relu'))\n",
    "        if self.depth > 1:\n",
    "            l = 0.3/(self.depth-1)\n",
    "        else:\n",
    "            l = 1\n",
    "        for d in range(1, self.depth):\n",
    "            depthi = str(d+1)\n",
    "            setattr(self, 'gcn{}'.format(depthi), GCN(nfi,nfi,'relu'))\n",
    "            drop = l*d+0.1\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = FC(nf0*nfi,256,'relu')\n",
    "        self.out = FC(256,nc,'softmax')\n",
    "    \n",
    "    def __call__(self,inputs):\n",
    "        depthi = '1'\n",
    "        x = getattr(self, 'gcn{}'.format(depthi))(inputs[0],inputs[1])\n",
    "        for d in range(1, self.depth):\n",
    "            depthi = str(d+1)\n",
    "            x = getattr(self, 'gcn{}'.format(depthi))(x,inputs[1])\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        y = self.out(x)\n",
    "        y = tuple([y])\n",
    "        return y\n",
    "    \n",
    "    def set_knn_out(self, knn_out):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = list(range(min(maxDs.keys()),max(maxDs.keys())+1))\n",
    "E = list(range(100,400,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = 0\n",
    "load_gcn_depth_results = True\n",
    "if load_gcn_depth_results:\n",
    "    NGScost = np.load(\"../data/gcn-depth/GScost_{}.npy\".format(di),allow_pickle=True)[()]\n",
    "    NGScost = NGScost[\"GScost\"]\n",
    "\n",
    "else:\n",
    "    Nexpr = 10\n",
    "\n",
    "\n",
    "    Nenum = list(product(list(range(Nexpr)), list(range(len(R))),list(range(len(E)))))\n",
    "    NGS = list(product(list(range(Nexpr)), R, E))\n",
    "\n",
    "    NGScost = np.zeros((Nexpr, len(R), len(E)))\n",
    "\n",
    "\n",
    "    for (n, r, e), (i, j,w) in zip(NGS,Nenum):\n",
    "        mygcn = GCNforDepth(Ahat.shape[1],4,r,8)\n",
    "        mygcn.train(train,e,print_return_history=False)\n",
    "        cost = mygcn.cost_mtr.metric_dataset(train)\n",
    "        NGScost[i,j,w] = cost\n",
    "        print('n exp: {}, r: {}, e: {}, cost: {}'.format(n,r,e,cost))\n",
    "\n",
    "\n",
    "\n",
    "    while True:\n",
    "        if not os.path.exists(\"GScost_{}.npy\".format(di)):\n",
    "            np.save(\"GScost_{}.npy\".format(di),\n",
    "                {\n",
    "                    \"GScost\": NGScost\n",
    "            })\n",
    "            break\n",
    "        di += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_mean = NGScost.mean(axis=(0,2))\n",
    "cost_std = NGScost.std(axis=(0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = True\n",
    "\n",
    "cost_mean_min = np.min(cost_mean)\n",
    "cost_mean_argmin = np.argmin(cost_mean)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(R, cost_mean, 'o-')\n",
    "plt.plot(R[cost_mean_argmin],cost_mean_min,'*r', markersize=12,label=r'$min \\; cost$')\n",
    "plt.legend(fontsize=12)\n",
    "plt.xlabel(r'$GCN \\; Depth \\; \\#$', fontsize=20)\n",
    "plt.ylabel(r'$Mean \\; Cost$', fontsize=20)\n",
    "plt.fill_between(R, cost_mean - cost_std,\n",
    "                     cost_mean + cost_std, alpha=0.1,\n",
    "                     color=\"b\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig('DataFigures/gcn-depth/{}.eps'.format('max-depth-grid-train'),format='eps')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (efthymis-mcl-MSc-Thesis)",
   "language": "python",
   "name": "pycharm-97527563"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
