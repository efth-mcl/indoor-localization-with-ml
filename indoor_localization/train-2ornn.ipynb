{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from models import Rnn\n",
    "from datasets import ZeroShotDataset\n",
    "from algomorphism.methods.nn import pca_denoising_preprocessing\n",
    "from algomorphism.figures.nn import pca_denoising_figure, print_confmtx\n",
    "from algomorphism.figures.nn import multiple_models_history_figure\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# optional for GPU usage\n",
    "\n",
    "# for gpu in tf.config.list_physical_devices('GPU'):\n",
    "#     print(gpu)\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_id = '64'\n",
    "embsD = 64\n",
    "\n",
    "dz = ZeroShotDataset(embs_id)\n",
    "labels = ['0','1','2']\n",
    "# all combinations seen (s), unseen (u):\n",
    "# {s: ['0','1'], u:['2']}, {s: ['0','2'], u:['1']}, {s: ['1','2'], u:['0']}\n",
    "seen_labels = ['0','2']\n",
    "unseen_labels = ['1']\n",
    "outfilekey = 's-{}-u-{}'.format('-'.join(seen_labels), '-'.join(unseen_labels))\n",
    "\n",
    "dz.load_data(seen_labels,unseen_labels)\n",
    "\n",
    "knn = KNeighborsClassifier(1)\n",
    "r_emb = dz.r_emb_disct_preprosesing(seen_labels, unseen_labels)\n",
    "X = tf.concat([r_emb[label].reshape(1,-1) for label in r_emb.keys()],axis=0)\n",
    "Xall = tf.concat([r_emb[key].reshape(1,-1) for key in r_emb.keys()],axis=0)\n",
    "labels_all = list(r_emb.keys())\n",
    "Y = dz.get_r_onehot_from_labels([label for label in r_emb.keys()])\n",
    "knn.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x, y_emb ,y, y1 in dz.val.unseen:\n",
    "    x = x.numpy()[np.where(\n",
    "        np.logical_and(\n",
    "            (y.numpy()==[1,0,0]).sum(axis=1)==3,\n",
    "            (y1.numpy()==[0,1]).sum(axis=1)==2\n",
    "        ))]\n",
    "    for i in range(x.shape[0]):\n",
    "        plt.figure(figsize=(8,2.5))\n",
    "        plt.plot(x[i],'-o')\n",
    "        plt.xlabel(r'$time(s)$')\n",
    "        plt.ylabel(r'$Normalized\\; UDP\\; Throughput$')\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = {'es_strategy':'patience', 'es_metric':'val_unseen_cost', 'es_patience': 10, 'es_min_delta': 1e-4}\n",
    "\n",
    "es = {'es_strategy':'first_drop', 'es_metric':'val_harmonic'}\n",
    "# add outfilekey as weights_outfile\n",
    "rnn = Rnn(dz, embsD, knn, es, weights_outfile=['.', outfilekey],\n",
    "          optimizer=\"Adam\", learning_rate=1e-4\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnn.train(dz, 200, ['train', 'val'])\n",
    "# rnn.load_weights(\"{}/weights/weights_best_{}.tf\".format('.', outfilekey))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_history_to_file = False\n",
    "if save_history_to_file:\n",
    "    with open('./data/2ornn/history-{}.json'.format(outfilekey), 'w') as outfile:\n",
    "            json.dump(rnn.history, outfile, indent=4)\n",
    "else:\n",
    "    with open('./data/2ornn/history-{}.json'.format(outfilekey), 'r') as f:\n",
    "        history = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj = ['.', '.', '2ornn', 'cost-score', outfilekey]\n",
    "multiple_models_history_figure([rnn], save_obj=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_seen = rnn.score_mtr.metric_dataset(dz.val.seen)\n",
    "val_unseen = rnn.score_mtr.metric_dataset(dz.val.unseen)\n",
    "\n",
    "print('val seen', val_seen)\n",
    "print('val unseen', val_unseen)\n",
    "print('HM', 2*val_seen*val_unseen/(val_seen + val_unseen))\n",
    "\n",
    "\n",
    "print_confmtx(rnn, dz, outfilekey+'_r_', -2, -2)\n",
    "print_confmtx(rnn, dz, outfilekey+'_a_', -1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dict, pca_emb, knn_pca= pca_denoising_preprocessing(rnn, dz, X, Y, pca_emb_idxs=[0, 1, 2], example_predicted_types=['val_seen', 'val_unseen'])\n",
    "save_obj = ['.','.','2ornn', 'node-emb', outfilekey]\n",
    "pca_denoising_figure(pca_dict, pca_emb, knn_pca, r_emb.keys(), save_obj=None, pca_emb_idxs=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# p_train = p_val = p_test = None\n",
    "# for x, _, _, _ in dz.train:\n",
    "#     p_train = rnn.call(x)\n",
    "# for x, _, _, _ in dz.val:\n",
    "#     p_val = rnn.call(x)\n",
    "# for x, _, _, _ in dz.test:\n",
    "#     p_test = rnn.call(x)\n",
    "#\n",
    "# concat = np.concatenate([Xall, p_train[0], p_val[0], p_test[0]])\n",
    "# mylist = labels_all+['train']*p_train[0].shape[0]+['val']*p_val[0].shape[0]+['test']*p_test[0].shape[0]\n",
    "#\n",
    "# ediml = np.array([\n",
    "#     (i, l) for i, l in enumerate(mylist)\n",
    "# ])\n",
    "# out = 'foo.tsv'\n",
    "# with open(\"./tensorboard_files/{}\".format(out), \"w\") as foo:\n",
    "#     text = \"idx\\tlabel\\n\"\n",
    "#     for c in ediml:\n",
    "#         text += '\\t'.join(c.tolist())\n",
    "#         text += '\\n'\n",
    "#     foo.write(text)\n",
    "#     foo.close()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %reload_ext tensorboard\n",
    "#\n",
    "# log_dir=\"./tensorboard_files/\"\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.makedirs(log_dir)\n",
    "# config = projector.ProjectorConfig()\n",
    "# embedding = config.embeddings.add()\n",
    "#\n",
    "# weights = tf.Variable(concat)\n",
    "# # Create a checkpoint from embedding, the filename and key are\n",
    "# # name of the tensor.\n",
    "# checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "# checkpoint.save(os.path.join(log_dir, \"embedding\"))\n",
    "#\n",
    "#\n",
    "# # The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`\n",
    "# embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "# # set tsv file\n",
    "# embedding.metadata_path = out\n",
    "# projector.visualize_embeddings(log_dir, config)\n",
    "#\n",
    "# # ref: from tensorflow site\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir=./tensorboard_files/ --host localhost --port 8882"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}