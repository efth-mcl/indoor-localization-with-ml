{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, LSTM, Bidirectional\n",
    "from tensorflow.keras.losses import MeanSquaredError as lMSE\n",
    "from tensorflow.keras.metrics import CosineSimilarity as mCosS\n",
    "from tensorflow.keras.metrics import MeanSquaredError as mMSE\n",
    "from thesispack.models import BaseNeuralNetwork, MetricBase, LossBase\n",
    "import tensorflow as tf\n",
    "from thesispack.methods import history_figure\n",
    "# from bayes_opt import BayesianOptimization\n",
    "# from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df=pd.read_csv(\n",
    "    StringIO(\n",
    "        str(\n",
    "            np.load(\"../data/Data.zip\")['RTT_data.csv'],\n",
    "            'utf-8'\n",
    "    )))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for k in df.keys():\n",
    "    print(k)\n",
    "    if k == \"channel_side1_ant1_tone  1\":\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dft_d = np.gradient(df['%Timestamp[s]'])\n",
    "new_m_ind = [0] + list(np.where(dft_d < -750)[0][::2]) + [len(df)]\n",
    "new_m_ind"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cnn_dataset(df, new_m_ind, dt=10):\n",
    "    max_pad = 0\n",
    "    tods_ap = []\n",
    "    spectrs_ap = []\n",
    "    ps_xy = []\n",
    "\n",
    "    for i in range(len(new_m_ind)-1):\n",
    "        dfmini = df.loc[new_m_ind[i]+2:new_m_ind[i+1]+1]\n",
    "\n",
    "        mint = dfmini[\"%Timestamp[s]\"].min()\n",
    "        dfmini[\"%Timestamp[s]\"] += -mint\n",
    "        widx = 0\n",
    "        while True:\n",
    "            tod_ap = []\n",
    "            spectr_ap = []\n",
    "            data = dfmini[(dfmini[\"%Timestamp[s]\"] <= dt*(widx+1)) & (dfmini[\"%Timestamp[s]\"] > dt*widx)].iloc[\n",
    "                :, :57+11\n",
    "            ]\n",
    "            if len(data) == 0:\n",
    "                break\n",
    "            for i in range(1, 13):\n",
    "                tod_ap.append(data[data[\"AP_index\"] == i][\"ToD_factor[m]\"].to_numpy())\n",
    "                spectr_ap.append(data[data[\"AP_index\"] == i].iloc[:, 11:].applymap(lambda x: np.abs(complex(x.replace('i', 'j')))).to_numpy())\n",
    "                if len(tod_ap[-1]) > max_pad:\n",
    "                    max_pad = len(tod_ap[-1])\n",
    "            tods_ap.append(tod_ap)\n",
    "            spectrs_ap.append(spectr_ap)\n",
    "            ps_xy.append(\n",
    "                np.mean(data[[\n",
    "                    'GroundTruthPositionX[m]',\n",
    "                    'GroundTruthPositionY[m]'\n",
    "                ]].to_numpy(),axis=0)\n",
    "            )\n",
    "            widx += 1\n",
    "    for i in range(len(tods_ap)):\n",
    "        tods_ap[i] = pad_sequences(tods_ap[i], padding=\"post\", maxlen=max_pad)\n",
    "        spectrs_ap[i] = pad_sequences(spectrs_ap[i], padding=\"post\", maxlen=max_pad)\n",
    "    tods_ap = tf.transpose(np.array(tods_ap), perm=[0,2,1]).numpy()\n",
    "    spectrs_ap = tf.transpose(np.array(spectrs_ap), perm=[0,2,1,3]).numpy()\n",
    "    ps_xy = np.array(ps_xy)\n",
    "\n",
    "    spectrs_ap = np.divide(spectrs_ap - np.mean(spectrs_ap, axis=(1, 0, 2)), np.std(spectrs_ap, axis=(1, 0, 2)))\n",
    "    tods_ap = np.divide(tods_ap - np.mean(tods_ap, axis=0), np.std(tods_ap, axis=0))\n",
    "    ps_xy = np.divide(ps_xy - np.mean(ps_xy, axis=0),  np.std(ps_xy, axis=0))\n",
    "\n",
    "    N_tr = tods_ap.shape[0]\n",
    "    np.random.seed(5287231)\n",
    "    Rarray = np.random.choice(np.arange(0, N_tr), replace=False, size=(1, N_tr)).reshape(N_tr)\n",
    "    tods_ap = tods_ap[Rarray]\n",
    "\n",
    "\n",
    "\n",
    "    ps_xy = ps_xy[Rarray]\n",
    "    train_tod, test_tod, train_spectr, test_spectr, train_pxy, test_pxy = train_test_split(tods_ap, spectrs_ap, ps_xy, test_size=0.33)\n",
    "\n",
    "\n",
    "    train_spectr_ap1 = train_spectr[:,:,0]\n",
    "    train_spectr_ap2 = train_spectr[:,:,1]\n",
    "    train_spectr_ap3 = train_spectr[:,:,2]\n",
    "    train_spectr_ap4 = train_spectr[:,:,3]\n",
    "    train_spectr_ap5 = train_spectr[:,:,4]\n",
    "    train_spectr_ap6 = train_spectr[:,:,5]\n",
    "    train_spectr_ap7 = train_spectr[:,:,6]\n",
    "    train_spectr_ap8 = train_spectr[:,:,7]\n",
    "    train_spectr_ap9 = train_spectr[:,:,8]\n",
    "    train_spectr_ap10 = train_spectr[:,:,9]\n",
    "    train_spectr_ap11 = train_spectr[:,:,10]\n",
    "    train_spectr_ap12 = train_spectr[:,:,11]\n",
    "\n",
    "    test_spectr_ap1 = test_spectr[:,:,0]\n",
    "    test_spectr_ap2 = test_spectr[:,:,1]\n",
    "    test_spectr_ap3 = test_spectr[:,:,2]\n",
    "    test_spectr_ap4 = test_spectr[:,:,3]\n",
    "    test_spectr_ap5 = test_spectr[:,:,4]\n",
    "    test_spectr_ap6 = test_spectr[:,:,5]\n",
    "    test_spectr_ap7 = test_spectr[:,:,6]\n",
    "    test_spectr_ap8 = test_spectr[:,:,7]\n",
    "    test_spectr_ap9 = test_spectr[:,:,8]\n",
    "    test_spectr_ap10 = test_spectr[:,:,9]\n",
    "    test_spectr_ap11 = test_spectr[:,:,10]\n",
    "    test_spectr_ap12 = test_spectr[:,:,11]\n",
    "\n",
    "    train = tf.data.Dataset.from_tensor_slices((\n",
    "                tf.cast(train_tod, tf.float32),\n",
    "                tf.cast(train_spectr_ap1, tf.float32),\n",
    "                tf.cast(train_spectr_ap2, tf.float32),\n",
    "                tf.cast(train_spectr_ap3, tf.float32),\n",
    "                tf.cast(train_spectr_ap4, tf.float32),\n",
    "                tf.cast(train_spectr_ap5, tf.float32),\n",
    "                tf.cast(train_spectr_ap6, tf.float32),\n",
    "                tf.cast(train_spectr_ap7, tf.float32),\n",
    "                tf.cast(train_spectr_ap8, tf.float32),\n",
    "                tf.cast(train_spectr_ap9, tf.float32),\n",
    "                tf.cast(train_spectr_ap10, tf.float32),\n",
    "                tf.cast(train_spectr_ap11, tf.float32),\n",
    "                tf.cast(train_spectr_ap12, tf.float32),\n",
    "                tf.cast(train_pxy, tf.float32),\n",
    "            )).batch(1000)\n",
    "\n",
    "    test = tf.data.Dataset.from_tensor_slices((\n",
    "                tf.cast(test_tod, tf.float32),\n",
    "                tf.cast(test_spectr_ap1, tf.float32),\n",
    "                tf.cast(test_spectr_ap2, tf.float32),\n",
    "                tf.cast(test_spectr_ap3, tf.float32),\n",
    "                tf.cast(test_spectr_ap4, tf.float32),\n",
    "                tf.cast(test_spectr_ap5, tf.float32),\n",
    "                tf.cast(test_spectr_ap6, tf.float32),\n",
    "                tf.cast(test_spectr_ap7, tf.float32),\n",
    "                tf.cast(test_spectr_ap8, tf.float32),\n",
    "                tf.cast(test_spectr_ap9, tf.float32),\n",
    "                tf.cast(test_spectr_ap10, tf.float32),\n",
    "                tf.cast(test_spectr_ap11, tf.float32),\n",
    "                tf.cast(test_spectr_ap12, tf.float32),\n",
    "                tf.cast(test_pxy, tf.float32),\n",
    "            )).batch(1000)\n",
    "\n",
    "    return train, test, tods_ap, spectrs_ap, ps_xy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rnn_dataset(df, new_m_ind, dt=10):\n",
    "    max_pad = 0\n",
    "    tods_ap = []\n",
    "    ps_xy = []\n",
    "    spectrs_ap = []\n",
    "\n",
    "    for i in range(len(new_m_ind)-1):\n",
    "        dfmini = df.loc[new_m_ind[i]+2:new_m_ind[i+1]+1]\n",
    "\n",
    "        mint = dfmini[\"%Timestamp[s]\"].min()\n",
    "        dfmini[\"%Timestamp[s]\"] += -mint\n",
    "        widx = 0\n",
    "        while True:\n",
    "            tod_ap = []\n",
    "            xy = []\n",
    "            spectr_ap = []\n",
    "            data = dfmini[(dfmini[\"%Timestamp[s]\"] <= dt*(widx+1)) & (dfmini[\"%Timestamp[s]\"] > dt*widx)].iloc[\n",
    "                :, :57+11\n",
    "            ]\n",
    "            if len(data) == 0:\n",
    "                break\n",
    "            for i in range(1, 13):\n",
    "                tod_ap.append(data[data[\"AP_index\"] == i][\"ToD_factor[m]\"].to_numpy())\n",
    "                spectr_ap.append(data[data[\"AP_index\"] == i].iloc[:, 11:].applymap(lambda x: np.abs(complex(x.replace('i', 'j')))).to_numpy())\n",
    "                xy.append(\n",
    "                    data[data[\"AP_index\"] == i][[\n",
    "                        'GroundTruthPositionX[m]',\n",
    "                        'GroundTruthPositionY[m]'\n",
    "                    ]].to_numpy()\n",
    "                )\n",
    "\n",
    "                if len(tod_ap[-1]) > max_pad:\n",
    "                    max_pad = len(tod_ap[-1])\n",
    "\n",
    "            xy = pad_sequences(xy, padding=\"post\")\n",
    "            xy = np.true_divide(xy.sum(0),(xy!=0).sum(0))\n",
    "            tods_ap.append(tod_ap)\n",
    "            spectrs_ap.append(spectr_ap)\n",
    "            xy = np.nan_to_num(xy)\n",
    "            ps_xy.append(xy)\n",
    "            widx += 1\n",
    "\n",
    "    for i in range(len(tods_ap)):\n",
    "        tods_ap[i] = pad_sequences(tods_ap[i], padding=\"post\", maxlen=max_pad)\n",
    "        spectrs_ap[i] = pad_sequences(spectrs_ap[i], padding=\"post\", maxlen=max_pad)\n",
    "        xy = ps_xy[i]\n",
    "        x = np.mean(xy[:, 0])\n",
    "        y = np.mean(xy[:, 1])\n",
    "        ps_xy[i] = np.array([x, y])\n",
    "\n",
    "    spectrs_ap = tf.transpose(np.array(spectrs_ap), perm=[0,2,1,3]).numpy()\n",
    "    tods_ap = tf.transpose(np.array(tods_ap), perm=[0,2,1]).numpy()\n",
    "    ps_xy = np.array(ps_xy)\n",
    "    spectrs_ap = np.divide(spectrs_ap - np.min(spectrs_ap, axis=(1, 0, 2)), np.max(spectrs_ap, axis=(1, 0, 2)) - np.min(spectrs_ap, axis=(1, 0, 2)))\n",
    "    tods_ap = np.divide(tods_ap - np.min(tods_ap, axis=(1, 0)), np.max(tods_ap, axis=(1, 0)) - np.min(tods_ap, axis=(1, 0)))\n",
    "    ps_xy = np.divide(ps_xy - np.min(ps_xy, axis=(0)),  np.max(ps_xy, axis=(0)) - np.min(ps_xy, axis=(0)))\n",
    "\n",
    "    N_tr = tods_ap.shape[0]\n",
    "    np.random.seed(5287231)\n",
    "    Rarray = np.random.choice(np.arange(0, N_tr), replace=False, size=(1, N_tr)).reshape(N_tr)\n",
    "    tods_ap = tods_ap[Rarray]\n",
    "    ps_xy = ps_xy[Rarray]\n",
    "    spectrs_ap = spectrs_ap[Rarray]\n",
    "\n",
    "    train_tod, test_tod, train_spectr, test_spectr, train_pxy, test_pxy = train_test_split(tods_ap, spectrs_ap, ps_xy, test_size=0.33)\n",
    "\n",
    "    train_spectr_ap1 = train_spectr[:,:,0]\n",
    "    train_spectr_ap2 = train_spectr[:,:,1]\n",
    "    train_spectr_ap3 = train_spectr[:,:,2]\n",
    "    train_spectr_ap4 = train_spectr[:,:,3]\n",
    "    train_spectr_ap5 = train_spectr[:,:,4]\n",
    "    train_spectr_ap6 = train_spectr[:,:,5]\n",
    "    train_spectr_ap7 = train_spectr[:,:,6]\n",
    "    train_spectr_ap8 = train_spectr[:,:,7]\n",
    "    train_spectr_ap9 = train_spectr[:,:,8]\n",
    "    train_spectr_ap10 = train_spectr[:,:,9]\n",
    "    train_spectr_ap11 = train_spectr[:,:,10]\n",
    "    train_spectr_ap12 = train_spectr[:,:,11]\n",
    "\n",
    "    test_spectr_ap1 = test_spectr[:,:,0]\n",
    "    test_spectr_ap2 = test_spectr[:,:,1]\n",
    "    test_spectr_ap3 = test_spectr[:,:,2]\n",
    "    test_spectr_ap4 = test_spectr[:,:,3]\n",
    "    test_spectr_ap5 = test_spectr[:,:,4]\n",
    "    test_spectr_ap6 = test_spectr[:,:,5]\n",
    "    test_spectr_ap7 = test_spectr[:,:,6]\n",
    "    test_spectr_ap8 = test_spectr[:,:,7]\n",
    "    test_spectr_ap9 = test_spectr[:,:,8]\n",
    "    test_spectr_ap10 = test_spectr[:,:,9]\n",
    "    test_spectr_ap11 = test_spectr[:,:,10]\n",
    "    test_spectr_ap12 = test_spectr[:,:,11]\n",
    "\n",
    "    train = tf.data.Dataset.from_tensor_slices((\n",
    "                tf.cast(train_tod, tf.float32),\n",
    "                tf.cast(train_spectr_ap1, tf.float32),\n",
    "                tf.cast(train_spectr_ap2, tf.float32),\n",
    "                tf.cast(train_spectr_ap3, tf.float32),\n",
    "                tf.cast(train_spectr_ap4, tf.float32),\n",
    "                tf.cast(train_spectr_ap5, tf.float32),\n",
    "                tf.cast(train_spectr_ap6, tf.float32),\n",
    "                tf.cast(train_spectr_ap7, tf.float32),\n",
    "                tf.cast(train_spectr_ap8, tf.float32),\n",
    "                tf.cast(train_spectr_ap9, tf.float32),\n",
    "                tf.cast(train_spectr_ap10, tf.float32),\n",
    "                tf.cast(train_spectr_ap11, tf.float32),\n",
    "                tf.cast(train_spectr_ap12, tf.float32),\n",
    "                tf.cast(train_pxy, tf.float32),\n",
    "            )).batch(1000)\n",
    "\n",
    "    test = tf.data.Dataset.from_tensor_slices((\n",
    "                tf.cast(test_tod, tf.float32),\n",
    "                tf.cast(test_spectr_ap1, tf.float32),\n",
    "                tf.cast(test_spectr_ap2, tf.float32),\n",
    "                tf.cast(test_spectr_ap3, tf.float32),\n",
    "                tf.cast(test_spectr_ap4, tf.float32),\n",
    "                tf.cast(test_spectr_ap5, tf.float32),\n",
    "                tf.cast(test_spectr_ap6, tf.float32),\n",
    "                tf.cast(test_spectr_ap7, tf.float32),\n",
    "                tf.cast(test_spectr_ap8, tf.float32),\n",
    "                tf.cast(test_spectr_ap9, tf.float32),\n",
    "                tf.cast(test_spectr_ap10, tf.float32),\n",
    "                tf.cast(test_spectr_ap11, tf.float32),\n",
    "                tf.cast(test_spectr_ap12, tf.float32),\n",
    "                tf.cast(test_pxy, tf.float32),\n",
    "            )).batch(1000)\n",
    "\n",
    "    return train, test, tods_ap, spectrs_ap, ps_xy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from bayes opt\n",
    "dt = 7.632100041832579\n",
    "# simple\n",
    "dt = 4\n",
    "train, test, _, _, _ = rnn_dataset(df, new_m_ind, dt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyCNN(tf.keras.layers.Layer):\n",
    "    def __init__(self, N, name=\"cnn\"):\n",
    "        super(MyCNN, self).__init__(name=name)\n",
    "\n",
    "        self.cnn1 = Conv1D(N,3,activation=None,\n",
    "                           bias_initializer=tf.keras.initializers.RandomUniform(minval=-0.5, maxval=0.5),\n",
    "                           name='cnn1')\n",
    "\n",
    "        self.cnn2 = Conv1D(N,3,activation=None,\n",
    "                           bias_initializer=tf.keras.initializers.RandomUniform(minval=-0.5, maxval=0.5),\n",
    "                           padding='same', name='cnn2')\n",
    "\n",
    "        self.sifmoid = tf.keras.activations.selu\n",
    "\n",
    "    def call(self, inpt):\n",
    "        x = self.cnn1(inpt)\n",
    "        x1 = self.sifmoid(x)\n",
    "\n",
    "        x = self.cnn2(x1)\n",
    "        x = x + x1\n",
    "        y = self.sifmoid(x)\n",
    "\n",
    "        return y\n",
    "\n",
    "class RTT_CNN1D(Model, BaseNeuralNetwork):\n",
    "\n",
    "    def __init__(self, early_stop_vars=None):\n",
    "        Model.__init__(self, name=\"rtt_cnn\")\n",
    "        status = [\n",
    "            [0],\n",
    "            [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0],\n",
    "            [1,2]\n",
    "        ]\n",
    "        BaseNeuralNetwork.__init__(self, status, early_stop_vars, None, \"Adam\", 1e-4)\n",
    "        self.score_mtr = MetricBase(self,\n",
    "            [mCosS()],\n",
    "            status,\n",
    "            [0]\n",
    "        )\n",
    "\n",
    "        self.cost_mtr = MetricBase(self,\n",
    "            [mMSE()],\n",
    "            status,\n",
    "            [0],\n",
    "            1\n",
    "        )\n",
    "\n",
    "        self.cost_loss = LossBase(self,\n",
    "          [lMSE()],\n",
    "          status,\n",
    "          [0]\n",
    "        )\n",
    "\n",
    "\n",
    "        self.cnn1 = MyCNN(128, 'cnn1')\n",
    "\n",
    "        cnnN = 64\n",
    "        self.cnn_ap1 = MyCNN(cnnN, 'cnn_ap1')\n",
    "        self.cnn_ap2 = MyCNN(cnnN, 'cnn_ap2')\n",
    "        self.cnn_ap3 = MyCNN(cnnN, 'cnn_ap3')\n",
    "        self.cnn_ap4 = MyCNN(cnnN, 'cnn_ap4')\n",
    "        self.cnn_ap5 = MyCNN(cnnN, 'cnn_ap5')\n",
    "        self.cnn_ap6 = MyCNN(cnnN, 'cnn_ap6')\n",
    "        self.cnn_ap7 = MyCNN(cnnN, 'cnn_ap7')\n",
    "        self.cnn_ap8 = MyCNN(cnnN, 'cnn_ap8')\n",
    "        self.cnn_ap9 = MyCNN(cnnN, 'cnn_ap9')\n",
    "        self.cnn_ap10 = MyCNN(cnnN, 'cnn_ap10')\n",
    "        self.cnn_ap11 = MyCNN(cnnN, 'cnn_ap11')\n",
    "        self.cnn_ap12 = MyCNN(cnnN, 'cnn_ap12')\n",
    "\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "        self.denseout = Dense(2,activation='sigmoid',name=\"denseout\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = self.cnn1(inputs[0])\n",
    "\n",
    "        x1 = self.cnn_ap1(inputs[1])\n",
    "        x2 = self.cnn_ap1(inputs[2])\n",
    "        x3 = self.cnn_ap1(inputs[3])\n",
    "        x4 = self.cnn_ap1(inputs[4])\n",
    "        x5 = self.cnn_ap1(inputs[5])\n",
    "        x6 = self.cnn_ap1(inputs[6])\n",
    "        x7 = self.cnn_ap1(inputs[7])\n",
    "        x8 = self.cnn_ap1(inputs[8])\n",
    "        x9 = self.cnn_ap1(inputs[9])\n",
    "        x10 = self.cnn_ap1(inputs[10])\n",
    "        x11 = self.cnn_ap1(inputs[11])\n",
    "        x12 = self.cnn_ap1(inputs[12])\n",
    "\n",
    "        xap = x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 + x12\n",
    "        x = self.concat([x , xap])\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        y = self.denseout(x)\n",
    "        return tuple((y,))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Ap_LSTM(tf.keras.layers.Layer):\n",
    "    def __init__(self, lstmN, return_s=False, bid=False):\n",
    "        def set_bid(lstmN, return_s, bid, name):\n",
    "            if bid:\n",
    "                return Bidirectional(\n",
    "                    LSTM(lstmN, return_sequences=return_s,\n",
    "                         bias_initializer=tf.keras.initializers.RandomUniform(minval=-2, maxval=2),\n",
    "                    ),\n",
    "                    name=name\n",
    "                )\n",
    "            else:\n",
    "                return LSTM(lstmN, return_sequences=return_s,name=name,\n",
    "                            bias_initializer=tf.keras.initializers.RandomUniform(minval=-2, maxval=2)\n",
    "                       )\n",
    "\n",
    "        super(Ap_LSTM, self).__init__(name='Ap_LSTM')\n",
    "        for i in range(1, lstmN+1):\n",
    "            setattr(\n",
    "                self,\n",
    "                'lstm_ap{}'.format(str(i)),\n",
    "                set_bid(lstmN, return_s, bid,'lstm_ap{}'.format(str(i)))\n",
    "            )\n",
    "\n",
    "    def call(self, inputs, comp_sum=False):\n",
    "        y = []\n",
    "        for i, inpt in enumerate(inputs):\n",
    "            y.append(\n",
    "                getattr(self, 'lstm_ap{}'.format(str(i+1)))(inpt)\n",
    "            )\n",
    "\n",
    "        if comp_sum:\n",
    "            y = sum(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class RTT_RNN(Model, BaseNeuralNetwork):\n",
    "    def __init__(self, early_stop_vars=None):\n",
    "        Model.__init__(self, name=\"rtt_rnn\")\n",
    "        status = [\n",
    "            [0],\n",
    "            [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0],\n",
    "            [1,2]\n",
    "        ]\n",
    "        BaseNeuralNetwork.__init__(self, status, early_stop_vars, None, \"Adam\", 1e-4)\n",
    "        self.score_mtr = MetricBase(self,\n",
    "            [mCosS()],\n",
    "            status,\n",
    "            [0]\n",
    "        )\n",
    "\n",
    "        self.cost_mtr = MetricBase(self,\n",
    "            [mMSE()],\n",
    "            status,\n",
    "            [0],\n",
    "            1\n",
    "        )\n",
    "\n",
    "        self.cost_loss = LossBase(self,\n",
    "          [lMSE()],\n",
    "          status,\n",
    "          [0]\n",
    "        )\n",
    "        self.lstm1 =  LSTM(32, return_sequences=True,name=\"lstm1\")\n",
    "        self.bidirectional1 = Bidirectional(self.lstm1,name=\"bidirectional1\")\n",
    "\n",
    "        self.lstm2 =  LSTM(32, return_sequences=False,name=\"lstm1\")\n",
    "        self.bidirectional2 = Bidirectional(self.lstm2,name=\"bidirectional2\")\n",
    "\n",
    "        lstmN = 32\n",
    "        self.ap_lstm1 = Ap_LSTM(lstmN,True, bid=True)\n",
    "        self.ap_lstm2 = Ap_LSTM(lstmN,False, bid=True)\n",
    "\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.dense = Dense(256,activation='tanh',name=\"dense\")\n",
    "\n",
    "        self.denseout = Dense(2,activation='sigmoid',name=\"denseout\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = self.bidirectional1(inputs[0])\n",
    "\n",
    "        x = self.bidirectional2(x)\n",
    "\n",
    "        xap = self.ap_lstm1(inputs[1:12], False)\n",
    "        xap = self.ap_lstm2(xap, True)\n",
    "\n",
    "        x = self.concat([x , xap])\n",
    "        x = self.dense(x)\n",
    "\n",
    "        y = self.denseout(x)\n",
    "        return tuple((y,))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rtt_cnn = RTT_CNN1D()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rtt_cnn.set_lr_rate(1e-4)\n",
    "rtt_cnn.set_clip_norm(0)\n",
    "rtt_cnn.train(train, 1000, test, history_learning_process=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "es = {'es_strategy':'patience', 'es_metric':'val_cost', 'es_min_delta': 1e-7, 'es_patience': 40 }\n",
    "rtt_rnn = RTT_RNN(early_stop_vars=es)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rtt_rnn.set_lr_rate(1e-4)\n",
    "rtt_rnn.set_early_stop({'es_strategy':'patience', 'es_metric':'val_cost', 'es_min_delta': 1e-7, 'es_patience': 40 })\n",
    "rtt_rnn.set_clip_norm(0)\n",
    "rtt_rnn.train(train, 600, test, history_learning_process=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_psxy(model, plotd='train', kfirst=10, save_obj=None):\n",
    "\n",
    "    if plotd == 'train':\n",
    "        for t in train:\n",
    "            pxy_t = t[-1]\n",
    "    elif plotd == 'test':\n",
    "        for t in test:\n",
    "            pxy_t = t[-1]\n",
    "\n",
    "    pxy_t_ = model(t)[0]\n",
    "    k = tf.reduce_sum(tf.subtract(pxy_t, pxy_t_)**2,axis=1)\n",
    "    k = tf.argsort(k)\n",
    "    k = k[:kfirst].numpy().tolist()\n",
    "    pxy_t = pxy_t.numpy()[k]\n",
    "    pxy_t_ = pxy_t_.numpy()[k]\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.scatter(pxy_t[:, 0], pxy_t[:, 1], marker='^', label='actual')\n",
    "    plt.scatter(pxy_t_[:, 0], pxy_t_[:, 1], marker='*', label='predict')\n",
    "    xtics = [-45.0, -35.0, -25.0, -15.0, -5.0, 5.0]\n",
    "    ytics = [-5, 0 , 5, 10, 15, 20]\n",
    "    plt.xticks(np.linspace(0,1,6), xtics, fontsize=16)\n",
    "    plt.yticks(np.linspace(0,1,6), ytics, fontsize=16)\n",
    "    plt.legend(fontsize=20)\n",
    "\n",
    "    if save_obj is not None:\n",
    "        plt.savefig('{}/DataFigures/{}-{}.svg'.format(*save_obj))\n",
    "    else:\n",
    "        plt.xticks(np.linspace(0,1,6), xtics, fontsize=16, color='red')\n",
    "        plt.yticks(np.linspace(0,1,6), ytics, fontsize=16, color='red')\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#train\n",
    "save_obj = ['.','outpout','train-top-20']\n",
    "plot_psxy(rtt_rnn, kfirst=20, save_obj=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#test\n",
    "save_obj = ['.','outpout','test-top-20']\n",
    "plot_psxy(rtt_rnn, kfirst=20, plotd='test', save_obj=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_obj = ['.','.','rtt-wifi','cost-score','']\n",
    "history_figure(rtt_rnn.history,save_obj=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}